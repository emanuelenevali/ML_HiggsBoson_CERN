{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Boson - ML Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from implementation import *\n",
    "from model_helpers import *\n",
    "from data_helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       ...,\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = { \n",
    "    'train' : 'data/train.csv',\n",
    "     'test' : 'data/test.csv',\n",
    "     'submission' : 'data/sample-submission.csv'\n",
    "        }\n",
    "\n",
    "y_tr, tx_tr, ids_tr = load_csv_data(paths['train'], sub_sample=False)\n",
    "y_te, tx_te, ids_te = load_csv_data(paths['test'])\n",
    "\n",
    "len_test = len(y_te)\n",
    "\n",
    "y_tr = y_tr[:, np.newaxis]\n",
    "y_pred = np.zeros(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree, initial_w, max_iters, gamma):\n",
    "    \"\"\"return the loss of ridge regression for a fold corresponding to k_indices\n",
    "    \n",
    "    Args:\n",
    "        y:          shape=(N,)\n",
    "        x:          shape=(N,)\n",
    "        k_indices:  2D array returned by build_k_indices()\n",
    "        k:          scalar, the k-th fold (N.B.: not to confused with k_fold which is the fold nums)\n",
    "        lambda_:    scalar, cf. ridge_regression()\n",
    "        degree:     scalar, cf. build_poly()\n",
    "        gamma:      scalar, stepsize\n",
    "\n",
    "    Returns:\n",
    "        train and test errors (probability of predicting correct values)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    train_id = np.delete(k_indices, k, axis=0).ravel()\n",
    "    test_id = k_indices[k]\n",
    "    \n",
    "    x_tr, y_tr = x[train_id], y[train_id]\n",
    "    x_te, y_te = x[test_id], y[test_id]\n",
    "    \n",
    "    x_tr, x_te = pre_processing(x_tr, x_te, poly_deg=degree, gamma=gamma)\n",
    "    \n",
    "    w, _ = reg_logistic_regression(y_tr, x_tr, lambda_, initial_w=initial_w, max_iters=max_iters, gamma=gamma)\n",
    "    \n",
    "    return (y_tr == predict_labels(w, x_tr)).mean(), (y_te == predict_labels(w, x_te)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_grid_search(txs, ys):\n",
    "    \"\"\"Runs cross validation on the data with different values of hyperparameters to compare accuracy\n",
    "    \n",
    "    Args:\n",
    "        txs: subsets of train dataset\n",
    "        ys:  labels of the different subsets\n",
    "        \n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    seed = 50\n",
    "    k_fold = 3\n",
    "    lambdas = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "    degrees = range(2, 8)\n",
    "    gammas = range(0, 11)\n",
    "    \n",
    "    # split data in k fold\n",
    "    k_indices = []\n",
    "    for i in range(len(txs)):\n",
    "        k_indices.append(build_k_indices(ys[i].shape[0], k_fold, seed))\n",
    "        \n",
    "    # cross validation\n",
    "    for i in range(len(txs)):\n",
    "        max_acc = 0\n",
    "        print(f\"*Set {i}\")\n",
    "        for l in lambdas:\n",
    "            for d in degrees:\n",
    "                for g in gammas:\n",
    "                    pred_pcts = []\n",
    "                    for k in range(k_fold):\n",
    "                        pred_pct = cross_validation(ys[i], txs[i], k_indices[i], k, l, d, g)\n",
    "                        pred_pcts.append(pred_pct)\n",
    "                    pct = np.mean(pred_pcts)\n",
    "                    if pct > max_acc:\n",
    "                        max_acc = pct\n",
    "                        print(f\">>>>Set {i}/lamdba={l}/deg={d}/gamma={g}/ACC={np.around(pct, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(txs, ys, lambda_, gamma):\n",
    "    \"\"\"Trains the classifier model\n",
    "    \n",
    "    Args:\n",
    "        txs: training data split into three subsets\n",
    "        y: labels of training data split into three subsets\n",
    "    \n",
    "    Returns:\n",
    "        ws: weights of each subsets.\n",
    "    \"\"\"\n",
    "    \n",
    "    ws = []\n",
    "    \n",
    "    for i in range(len(txs)):\n",
    "        weights, loss = reg_logistic_regression(ys[i], txs[i], lambda_=lambda_, initial_w=np.zeros((txs[i].shape[1], 1)), max_iters=1000, gamma=gamma)\n",
    "        ws.append(weights)\n",
    "        \n",
    "    return ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(txs_te, ws):\n",
    "    \"\"\"Generate the predictions and save ouput\n",
    "    \n",
    "    Args:\n",
    "        txs_te: subsets of test dataset\n",
    "        ws: weights of the different subsets\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    mask_test = get_jet_indexes(tx_test)\n",
    "    for j in range(len(txs_test)):\n",
    "            y_pred[mask_test[j]] = [i[0] for i in predict_labels(ws[j], txs_test[j])]\n",
    "            \n",
    "    create_csv_submission(ids_test, y_pred, paths['submission'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
