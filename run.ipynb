{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Boson - ML Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from implementation import *\n",
    "from model_helpers import *\n",
    "from data_helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = { \n",
    "    'train' : 'data/train.csv',\n",
    "     'test' : 'data/test.csv',\n",
    "     'submission' : 'data/sample-submission.csv'\n",
    "        }\n",
    "\n",
    "y_tr, tx_tr, ids_tr = load_csv_data(paths['train'], sub_sample=False)\n",
    "y_te, tx_te, ids_te = load_csv_data(paths['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test = len(y_te)\n",
    "\n",
    "y_tr = y_tr[:, np.newaxis]\n",
    "y_pred = np.zeros(len_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tr = get_mask(tx_tr)\n",
    "mask_te = get_mask(tx_te)\n",
    "\n",
    "x_tr_subsamples = []\n",
    "y_tr_subsamples = []\n",
    "\n",
    "x_te_subsamples = []\n",
    "\n",
    "# create subsamples\n",
    "for i in range(4):\n",
    "    x_tr_subsamples.append(tx_tr[mask_tr[i]])\n",
    "    y_tr_subsamples.append(y_tr[mask_tr[i]])\n",
    "    x_te_subsamples.append(tx_te[mask_te[i]])\n",
    "    \n",
    "# pre-process each subsample\n",
    "for id in range(4):\n",
    "    x_tr_subsamples[i] = pre_processing(x_tr_subsamples[i])\n",
    "    x_te_subsamples[i] = pre_processing(x_te_subsamples[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree, gamma, max_iters=500):\n",
    "    \"\"\"return the loss of ridge regression for a fold corresponding to k_indices\n",
    "    \n",
    "    Args:\n",
    "        y:          shape=(N,)\n",
    "        x:          shape=(N,)\n",
    "        k_indices:  2D array returned by build_k_indices()\n",
    "        k:          scalar, the k-th fold (N.B.: not to confused with k_fold which is the fold nums)\n",
    "        lambda_:    scalar, cf. ridge_regression()\n",
    "        degree:     scalar, cf. build_poly()\n",
    "        gamma:      scalar, stepsize\n",
    "\n",
    "    Returns:\n",
    "        train and test errors (probability of predicting correct values)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    train_id = np.delete(k_indices, k, axis=0).ravel()\n",
    "    test_id = k_indices[k]\n",
    "    \n",
    "    x_tr, y_tr = x[train_id], y[train_id]\n",
    "    x_te, y_te = x[test_id], y[test_id]\n",
    "    \n",
    "    x_tr, x_te = build_poly(x_tr,degree), build_poly(x_te,degree)\n",
    "    \n",
    "    w, _ = reg_logistic_regression(y_tr, x_tr, lambda_, np.zeros((x_tr.shape[1], 1)), max_iters, gamma)\n",
    "    \n",
    "    return (y_te == predict_labels(x_te, w)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_grid_search(txs, ys):\n",
    "    \"\"\"Runs cross validation on the data with different values of hyperparameters to compare accuracy\n",
    "    \n",
    "    Args:\n",
    "        txs: subsets of train dataset\n",
    "        ys:  labels of the different subsets\n",
    "        \n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    seed = 51\n",
    "    k_fold = 4\n",
    "    lambdas = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "    degrees = range(2, 6)\n",
    "    gammas = [1e-3, 1e-2, 1e-1]\n",
    "    \n",
    "    # split data in k fold\n",
    "    k_indices = []\n",
    "    for i in range(len(txs)):\n",
    "        k_indices.append(build_k_indices(ys[i].shape[0], k_fold, seed))\n",
    "        \n",
    "    # cross validation\n",
    "    for i in range(len(txs)):\n",
    "        max_acc = 0\n",
    "        print(f\"*Set {i}\")\n",
    "        for l in lambdas:\n",
    "            for d in degrees:\n",
    "                for g in gammas:\n",
    "                    pred_pcts = []\n",
    "                    for k in range(k_fold):\n",
    "                        pred_pct = cross_validation(ys[i], txs[i], k_indices[i], k, l, d, g)\n",
    "                        pred_pcts.append(pred_pct)\n",
    "                    pct = np.mean(pred_pcts)\n",
    "                    if pct > max_acc:\n",
    "                        max_acc = pct\n",
    "                    print(f\">>>>Set {i}/lamdba={l}/deg={d}/gamma={g}/ACC={np.around(pct, 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Set 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infos\\OneDrive\\Desktop\\epfl\\ML\\progetto 1 rep gruppo\\ML_project1\\model_helpers.py:82: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-t))\n",
      "C:\\Users\\infos\\OneDrive\\Desktop\\epfl\\ML\\progetto 1 rep gruppo\\ML_project1\\model_helpers.py:97: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.mean(y*np.log(sigmoid(dot)) + (1-y)*np.log(1-sigmoid(dot)))\n",
      "C:\\Users\\infos\\OneDrive\\Desktop\\epfl\\ML\\progetto 1 rep gruppo\\ML_project1\\model_helpers.py:97: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.mean(y*np.log(sigmoid(dot)) + (1-y)*np.log(1-sigmoid(dot)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>Set 0/lamdba=1e-05/deg=2/gamma=0.001/ACC=0.6514432701\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcross_validation_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr_subsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tr_subsamples\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mcross_validation_grid_search\u001b[1;34m(txs, ys)\u001b[0m\n\u001b[0;32m     28\u001b[0m pred_pcts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_fold):\n\u001b[1;32m---> 30\u001b[0m     pred_pct \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     pred_pcts\u001b[38;5;241m.\u001b[39mappend(pred_pct)\n\u001b[0;32m     32\u001b[0m pct \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(pred_pcts)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(y, x, k_indices, k, lambda_, degree, gamma, max_iters)\u001b[0m\n\u001b[0;32m     22\u001b[0m x_te, y_te \u001b[38;5;241m=\u001b[39m x[test_id], y[test_id]\n\u001b[0;32m     24\u001b[0m x_tr, x_te \u001b[38;5;241m=\u001b[39m build_poly(x_tr,degree), build_poly(x_te,degree)\n\u001b[1;32m---> 26\u001b[0m w, _ \u001b[38;5;241m=\u001b[39m \u001b[43mreg_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (y_te \u001b[38;5;241m==\u001b[39m predict_labels(x_te, w))\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\epfl\\ML\\progetto 1 rep gruppo\\ML_project1\\implementation.py:153\u001b[0m, in \u001b[0;36mreg_logistic_regression\u001b[1;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m    151\u001b[0m w \u001b[38;5;241m=\u001b[39m initial_w\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[1;32m--> 153\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mreg_lr_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     g \u001b[38;5;241m=\u001b[39m reg_lr_compute_gradient(y,tx,w,lambda_)\n\u001b[0;32m    155\u001b[0m     w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m gamma\u001b[38;5;241m*\u001b[39mg\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\epfl\\ML\\progetto 1 rep gruppo\\ML_project1\\model_helpers.py:119\u001b[0m, in \u001b[0;36mreg_lr_compute_loss\u001b[1;34m(y, tx, w, lambda_)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreg_lr_compute_loss\u001b[39m(y, tx, w, lambda_):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Computation of the regularized logistic loss (negative log likelihood)\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    INPUTS: y = target, tx = sample matrix, w = weights vector\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    OUTPUTS: evaluation of the loss\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlr_calculate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m lambda_\u001b[38;5;241m*\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(w,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\epfl\\ML\\progetto 1 rep gruppo\\ML_project1\\model_helpers.py:97\u001b[0m, in \u001b[0;36mlr_calculate_loss\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\"Loss for logistic regression.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m dot \u001b[38;5;241m=\u001b[39m tx\u001b[38;5;129m@w\u001b[39m\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(y\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(sigmoid(dot)) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39my)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\epfl\\ML\\progetto 1 rep gruppo\\ML_project1\\model_helpers.py:82\u001b[0m, in \u001b[0;36msigmoid\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid\u001b[39m(t):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124;03m\"\"\"Applies sigmoid function on t.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m        s(t): element to which the sigmoid function has been applied.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cross_validation_grid_search(x_tr_subsamples,y_tr_subsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(txs, ys, lambda_, gamma, degree):\n",
    "    \"\"\"Trains the classifier model\n",
    "    \n",
    "    Args:\n",
    "        txs: training data split into three subsets\n",
    "        y: labels of training data split into three subsets\n",
    "    \n",
    "    Returns:\n",
    "        ws: weights of each subsets.\n",
    "    \"\"\"\n",
    "    \n",
    "    ws = []\n",
    "    \n",
    "    for i in range(len(txs)):\n",
    "        x_poly = build_poly(txs[i],degree)\n",
    "        weights, loss = reg_logistic_regression(ys[i], x_poly, lambda_=lambda_, initial_w=np.zeros((x_poly.shape[1], 1)), max_iters=1000, gamma=gamma)\n",
    "        ws.append(weights)\n",
    "        \n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_, gamma, degree = 1e-5, 1e-2, 4\n",
    "\n",
    "ws = train_model(x_tr_subsamples, y_tr_subsamples, lambda_, gamma, degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(txs_te, ws, mask_test, y_pred):\n",
    "    \"\"\"Generate the predictions and save ouput\n",
    "    \n",
    "    Args:\n",
    "        txs_te: subsets of test dataset\n",
    "        ws: weights of the different subsets\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    for j in range(len(txs_te)):\n",
    "            y_pred[mask_test[j]] = [y[0] for y in predict_labels(build_poly(txs_te[j],degree), ws[j])]\n",
    "            \n",
    "    create_csv_submission(ids_te, y_pred, paths['submission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions(x_te_subsamples, ws, mask_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
